{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2719e241",
   "metadata": {},
   "source": [
    "# FY 2018 Endangered Species Expenditures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70e21df7",
   "metadata": {},
   "source": [
    "### Data Source:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "480d1459",
   "metadata": {},
   "source": [
    "2018 Endangered Species Expenditures Data was collected from the following public report on pages 8-104:\n",
    "https://www.fws.gov/sites/default/files/documents/endangered-and-threatened-species-expenditures-fiscal-year-2018.pdf\n",
    "\n",
    "Note: This does not include expenditures for land acquistion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8765398f",
   "metadata": {},
   "source": [
    "### Module Imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f6f12655",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tabula as tb\n",
    "import re\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "sns.set(rc = {'figure.figsize':(15,8)}, color_codes=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4afcac0",
   "metadata": {},
   "source": [
    "### Data Cleaning:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a62fa5",
   "metadata": {},
   "source": [
    "First I converted table 1 in the pdf to a csv file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4830c5f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Expected 9 fields in line 344, saw 10\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/y9/fzcglvx51gb_4cpw72hcn17m0000gp/T/ipykernel_45010/4159414645.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mfile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'endangered-and-threatened-species-expenditures-fiscal-year-2018.pdf'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_into\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"expenditures2018.csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpage_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_format\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;34m\"csv\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expenditures2018.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Expected 9 fields in line 344, saw 10\n"
     ]
    }
   ],
   "source": [
    "page_list = list(range(8, 105))\n",
    "file = 'endangered-and-threatened-species-expenditures-fiscal-year-2018.pdf'\n",
    "tb.convert_into(file, \"expenditures2018.csv\", pages = page_list, output_format =\"csv\", stream = True)\n",
    "df = pd.read_csv('expenditures2018.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5da82b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91327c7e",
   "metadata": {},
   "source": [
    "After viewing a snapshot of the data, I realized that there were inconsistencies columns and rows needed to be manually cleaned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa2795a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# after cleaning renamed data to 'cleaned_expenditures2018.csv'\n",
    "df2018 = pd.read_csv('cleaned_expenditures2018.csv')\n",
    "print(df2018.columns)\n",
    "df2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d72e5191",
   "metadata": {},
   "source": [
    "Renaming columns for consistency across dataframes & splitting combined columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4206e57",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018 = df2018.rename(columns={'Species ':'Species',\n",
    "                                'Group Name':'Group',\n",
    "                                'FWS Total':'FWS 2018',\n",
    "                                'Other Fed':'Other Fed 2018',\n",
    "                                'States Total':'States 2018', \n",
    "                                'Species Total':'Total 2018'})\n",
    "# split column and add new columns to df\n",
    "df2018[['Inverted Common Name','Scientific Name',\n",
    "        'Noname1', 'Noname2', 'Noname3', 'Noname4' ]] = df2018['Species'].str.split('(', expand=True)\n",
    "df2018[['Scientific Name','Area', 'Noname5', 'Noname6', 'Noname7']] = df2018['Scientific Name'].str.split('-', expand=True)\n",
    "\n",
    "#drop extra columns\n",
    "df2018 = df2018.drop(['Rank','Federal Total','Species','Noname1',\n",
    "                      'Noname2','Noname3','Noname4','Noname5',\n",
    "                      'Noname6','Noname7'], axis = 1)\n",
    "df2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83fabc4",
   "metadata": {},
   "source": [
    "In order to perform EDA, needed to remove symbols and change data types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8629c285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove unnecessary symbols\n",
    "df2018['Scientific Name'] = df2018['Scientific Name'].str.replace('[()=]', '', regex=True)\n",
    "\n",
    "#changed data type to integer for analysis\n",
    "df2018['Total 2018'] = df2018['Total 2018'].str.replace('[/$,]', '', regex=True).astype(int)\n",
    "df2018['States 2018'] = df2018['States 2018'].str.replace('[/$,]', '', regex=True).astype(int)\n",
    "df2018['FWS 2018'] = df2018['FWS 2018'].str.replace('[/$,]', '', regex=True).astype(int)\n",
    "df2018['Other Fed 2018'] = df2018['Other Fed 2018'].str.replace('[/$,]', '', regex=True).astype(int)\n",
    "\n",
    "# display the dataframe\n",
    "df2018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1821139d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df2018.shape)\n",
    "# checking the stats for the expenditures\n",
    "df2018.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95020617",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018.groupby(\"Group\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbce2b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Changing the order of the columns displayed\n",
    "df2018 = df2018[['Group','Status','Scientific Name','Inverted Common Name',\n",
    "        'FWS 2018','Other Fed 2018','States 2018','Total 2018','Area']]\n",
    "\n",
    "#sorting the values by 'Group' and resetting the index\n",
    "df2018.sort_values(by=['Group'], inplace=True)\n",
    "df2018 = df2018.reset_index()\n",
    "df2018 = df2018.drop(['index'], axis = 1)\n",
    "\n",
    "df2018.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e51718e",
   "metadata": {},
   "source": [
    "Now that the index is reset, I can use the group count totals from groupby(\"Group\").size() to drop the group subtotal rows that could skew my analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "556dd21f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to preserve df2017, I made a copy\n",
    "df2018_copy = df2018\n",
    "\n",
    "# performing the drop on the copy only\n",
    "df2018_copy = df2018_copy.drop(index=[\n",
    "    38,50,161,274,279,296,323,362,543,\n",
    "    1433,1522,1525,1647,1648,1709,1760,1761]) \n",
    "\n",
    "# checking to make sure that only the subtotals were dropped\n",
    "df2018_copy['Group'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af35a7c",
   "metadata": {},
   "source": [
    "Now that the subtotal rows are dropped:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa15e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking the null values.\n",
    "print(df2018_copy.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47e857f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#checking display before exporting\n",
    "df2018_copy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ad036d",
   "metadata": {},
   "source": [
    "Now the dataframe is ready for analysis. I convert the copy (without subtotals) to a new csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f27dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df2018_copy.to_csv('esa_expenditures2018.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
